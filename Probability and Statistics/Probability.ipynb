{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e6aa53",
   "metadata": {},
   "source": [
    "# Probability\n",
    "Author: Vo, Huynh Quang Nguyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46992b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44719ceb",
   "metadata": {},
   "source": [
    "# Acknowledgements:\n",
    "The contents of this note are based on the lecture notes and the materials from the sources listed below:\n",
    "\n",
    "1. _Essential Math for Data Science_ in 6 Weeks webinar given by Dr. Thomas Nield.\n",
    "Available in O'Reily Learning: [Essential Math for Data Science in 6 Weeks](https://learning.oreilly.com/attend/essential-math-for-data-science-in-6-weeks/0636920055929/0636920055928/)\n",
    "\n",
    "\n",
    "2. _Probability Cheatsheet v2.0_ given by William Chen, and Joe Blitzstein, with contributions from Sebastian Chiu, Yuan Jiang, Yuqi Hou, and Jessy Hwang.\n",
    "Available in Github: [http://github.com/wzchen/probability_cheatsheet]\n",
    "\n",
    "\n",
    "3. _Deep Learning_ textbook by Dr. Ian Goodfellow, Prof. Yoshua Bengio, and Prof. Aaron Courville. The book is available for public access via an designated website: [Deep Learning textbook](https://www.deeplearningbook.org/)\n",
    "\n",
    "\n",
    "4. _Introduction to Probability and Statistics for Engineers and Scientists_ textbook by Prof. Sheldon Ross from University of Southern California.\n",
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a4b75",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Introduction to Probability](#Section1)\n",
    "2. [Overview of Probability](#Section2)\n",
    "3. [Advanced Topics in Probability](#Section3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc2101",
   "metadata": {},
   "source": [
    "# I. Introduction to Probability <a name = \"Section1\"></a>\n",
    "## 1. Why do we care about probability?\n",
    "1. Machine learning must always deal with uncertain quantities, and sometimes may also need to deal with stochastic (non-deterministic) quantities which come from many sources. There are three main sources:\n",
    "     * **Inherent stochasticity** in the system being modeled. For example, the dynamics of subatomic particles in quantum mechanics systems are probabilistic, or a hypothetical card game where we assume that the cards are truly shuﬄed into a random order.\n",
    "     * **Incomplete observability**. Even deterministic systems can appear stochastic when we cannot observe all of the variables that drive the behavior of the system. For example, in the Monty Hall problem, the outcome given the contestant’s choice is deterministic but uncertain from the contestant's point of view.\n",
    "     * **Incomplete modeling**. For example, when we use a model that must discard some of the information we have observed, the discarded information results in uncertainty in the model’s predictions.\n",
    "\n",
    "\n",
    "2. Noted that the term _stochasticity_ refers to randomnes. Meanwhile, the term _determinism_ refers to a type of system in which the outputs are always the same given starting conditions or initial state.\n",
    "\n",
    "<div>\n",
    "    <img src = \"images/monty_hall.png\" width = 100%/>\n",
    "    </div>\n",
    "\n",
    "Figure 1: Visualization of the famous Monty Hall problem and its decision flowchart (adapted from **Brilliant Math & Science Wiki**). Monty Hall problem is a thought-experiment where you are asked to open three doors. Behind each door, there is either a car or a goat. You choose a door. The host, Monty Hall, picks one of the other doors, which he knows has a goat behind it, and opens it, showing you the goat. Monty then asks whether you would like to switch your choice of door to the other remaining door. Assuming you prefer having a car more than having a goat, and according to the game rules the host will always reveal a goat, do you choose to switch or not to switch? This thought experiment is a prime example of incomplete observability.\n",
    "\n",
    "\n",
    "## 2. Applications of probability\n",
    "Together with linear algebra, statistics and multivariate calculus, probability plays a crucial role in machine learning. Below are several examples of its application in machine learning.\n",
    "\n",
    "<div>\n",
    "    <img src=\"images/naive_bayes.png\" />\n",
    "    </div>\n",
    "    \n",
    "Figure 2: Illustration behind the Naive Bayes algorithm. In this algorithm, we estimate the probability distribution of our data ($P(x_{\\alpha}|y)$) independently in each dimension, and then obtain an estimate of the full data distribution by assuming conditional independence $P(x|y)=\\prod_{\\alpha} P(x_{\\alpha}|y)$. \n",
    "\n",
    "## 3. Probability vs. statistics\n",
    "1. Probability and statistics often get confused and said interchangeably, but there is a distinction:\n",
    "    * Probability is solely about studying likelihood.\n",
    "    * Statistics utilizes data to discover likelihood.\n",
    "\n",
    "\n",
    "2. In practicality, these two things are going to be tightly tied together, as one can argue it is hard to have probability without data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fb0a7",
   "metadata": {},
   "source": [
    "# II. Overview of Probability <a name = \"Section2\"></a>\n",
    "## 1. What is probability?\n",
    "1. We can simply understand probability as how likely an event will happen, based on observations or belief. Some examples of probability are:\n",
    "    * How likely is it we will get 7 heads in 10 fair coin flips?\n",
    "    * What is the likelihood our flight will be late?\n",
    "    * How certain are we that a product is defective?\n",
    "    \n",
    "    \n",
    "2. Probability is expressed in two ways:\n",
    "    * As a percentage: 60% chance our flight will be late \n",
    "    * As a ratio: 3:2 odds our flight will be late\n",
    "    \n",
    "    \n",
    "## 2. Probability philosophies\n",
    "There are two philosophies of probability:\n",
    "1. **Frequentist probability**, which is the most popularly understood approach to probability, believes that the frequency of an event provides hard evidence of the probability ~ related directly to the rates at which events occur.\n",
    "    * This implies if we repeated an event infinitely many times, then proportion $p$ of the repetitions would result in that outcome. Therefore, if we gather more data, we will increase confidence in the probability. \n",
    "    * Frequentist probability tends to work best when a lot of data is available, reliable, and complete.\n",
    "    * Commonly used tools include p-values, confidence intervals, prediction intervals, tolerance intervals, etc.\n",
    "    * Noted that when we are prefering probability as frequentist, we usually use the term chance.\n",
    "    \n",
    "    \n",
    "2. **Bayesian probability**, which is much more abstract in that it assigns subjective beliefs in a probability and not just data ~ related to the degree of belief.\n",
    "    * This implies an arbitrary probability can be assigned based on subjective beliefs, and then data can be used to gradually update that belief.\n",
    "    * Bayesian methods tend to work well when data is limited, a large amount of domain knowledge is present, or uncertainty is hard to eliminate. \n",
    "    * Bayesian tools include the Bayes factor and credible intervals. \n",
    "$$\n",
    "$$\n",
    "<div>\n",
    "    <img src = 'images/bayes_example.png' width = 35%>\n",
    "    </div>\n",
    "\n",
    "Figure 1: An example of Bayesian probability: imagine we are flipping coin, and we know that a coin has a 50% chance of landing a **head**. We flip a coin 10 times, and get 7 heads simultaneously. As a result, we update the beta distribution of the **head** (to the right) and see there are greater likelihoods of heads being more than 50%. \n",
    "\n",
    "## 3. Fundamentals of probability\n",
    "### a) Basics of probability\n",
    "1. As mentioned above, we understand that probability is a measure of how likely an outcome $x$ is. Probability is typically represented as a number $P(x)$ between 0.0 and 1.0, or as a percentage between 0% and 100%.\n",
    "\n",
    "\n",
    "2. The probability of an event $P(x)$ not occurring can be calculated by $1.0 − P(x)$, which indicates both outcomes must add to 1.0. \n",
    "\n",
    "\n",
    "3. When we work with a single simple probability, it is known as a marginal probability.\n",
    "\n",
    "\n",
    "4. As mentioned above, we know that probability can be based on data, a belief, or both.\n",
    "    * Based on data: as an example, if we sample 10 products from a factory line and find 4 items are defective, that would be a 40% defective rate.\n",
    "    * Based on belief: as an example, an engineer realizes an inferior material was used and guesses the defective rate for the product will be 50%. \n",
    "    * Based on data + belief: we can quantify the engineer’s belief and the data, merge them together, and find a 44.44% probability is most likely.\n",
    "\n",
    "#### Expressing probability as odds\n",
    "1. We know that probability can be expressed as an odds ratio which means how many times we believe in something being true versus not being true. Odd ratios are also a helpful way to quantify subjective beliefs by means of “betting.”\n",
    "\n",
    "\n",
    "2. Consider this example, if a friend of us is willing to pay us 200$\\$$ if the Vietnamese football team can be qualified for the World Cup 2022, but we must pay him 50$\\$$ if they do not, that means he believes the Vietnamese football team are 4x more likely to fail rather than succeed $\\frac{200}{50} = 4.0$. In another case, if he pays 200$\\$$ for them succeeding but I must pay him 1$\\$$ if they don't, that means he REALLY believes the Vietnamese team are going to fail: 200x more likely ($\\frac{200}{1}=200$). \n",
    "\n",
    "\n",
    "#### Turning Odds into Probabilities\n",
    "1. We can turn an odds ratio $O(x)$ into a probability by using the following formula:\n",
    "$$\n",
    "P(x) = \\frac{O(x)}{1 + O(x)}\n",
    "$$\n",
    "\n",
    "2. Let's consider the previous example, we can quantify our friend's belief as:\n",
    "$$\n",
    "P_1(x) = \\frac{200}{200 + 5} \\approx 0.976 \n",
    "$$\n",
    "\n",
    "$$\n",
    "P_2(x) = \\frac{200}{200 + 1} \\approx 0.995\n",
    "$$\n",
    "\n",
    "\n",
    "### b) Random variable\n",
    "1. In probabilistic modeling and computation, a random variable $\\mathbf{x}$ is a variable that can take on different values randomly:\n",
    "    * A random variables can be a vector-valued variables $\\mathbf{x} = [x_1, x_2, ..., x_n]$.\n",
    "    * On its own, a random variable is a description of the states that are possible. Therefore, it must be coupled with a probability distribution that specifies how likely each of these states are.\n",
    "    * Random variables may be discrete or continuous. A discrete random variable is one that has a finite or countably infinite number of states. A continuous random variable is associated with a real value.\n",
    "\n",
    "\n",
    "### c) Probabilistic computation\n",
    "\n",
    "#### Joint probabilities\n",
    "1. Imagine we have two events that occur independently meaning they do not affect each other's outcomes, the probability of both events occurring simultanenously is:\n",
    "$$\n",
    "P(A\\cap B) = P(A,B) = P(A) \\times P(B)\n",
    "$$\n",
    "\n",
    "\n",
    "2. For example, consider the probability of flipping a coin and getting a  (Event A), and of rolling of a dice and getting a six (Event B).  Since A and B are independent, the probability of both events occurr simultaneously is:\n",
    "$$\n",
    "P(A\\cap B) = \\frac{1}{2} \\times \\frac{1}{6} = \\frac{1}{12}\n",
    "$$\n",
    "\n",
    "\n",
    "3. Joint probabilities work on the so-called product rule, and we can use this to combine as many probabilities as we want. \n",
    "\n",
    "#### Union probabilites\n",
    "1. There are two kinds of union probabilites: mutually exclusive (m.u) and non-mutually exclusive (n.m.u).\n",
    "\n",
    "\n",
    "2. When two events are mutually exclusive, meaning that only one of the events can occur but not both, then the resulting probability is the sum of individual event's probability. For example, we want to compute the probability of getting a “4” or “6” on a die roll: because we cannot get “4” and a “6” simultaneously, we just add these probabilities together.\n",
    "$$\n",
    "P(A\\cup B) = \\frac{1}{6}\\times \\frac{1}{6} = \\frac{1}{3}\n",
    "$$\n",
    "\n",
    "\n",
    "3. When two events are non-mutually exclusive, meaning that two events can occur simultaneously, then the resulting probability follows the so-called sum rule. For example, we want to compute the probability of getting a prime or even number on a die roll.\n",
    "$$\n",
    "P(A\\cup B) = P(A) + P(B) - P(A\\cap B)\n",
    "$$\n",
    "\n",
    "\n",
    "4. Noted that the sum rule is applicable for all union probabilities: in non-mutually exclusive events, the joint probability is zero. Similar to the product rule, we can apply the sum rule for as many probabilities as we like.\n",
    "<div>\n",
    "    <img src =\"images/union_probabilities.png\"/>\n",
    "    </div>\n",
    "    \n",
    "Figure 2: An example of union probability. Consider a card deck, the mutually exclusive events are Aces and Kings because they cannot occurr simultaneously (a). Meanwhile, the non-mutually exclusive events are Hearts and Kings because they can occur simultaneously (b). If we want to compute the n.m.u, we must deduct the joint probability to avoid counting the latter repeatly.\n",
    "\n",
    "\n",
    "#### Conditional probability\n",
    "1. Conditional probability describe the probability Event A occurs given Event B $P(A|B)$ occurs:\n",
    "    * If Event B has no impact on whether Event A occurs, then $P(A) = P(A|B)$.\n",
    "    * If Event B does impact on Event A by increasing or decreasing the latter's probability, then $P(A)\\neq P(A|B)$.\n",
    "\n",
    "\n",
    "2. The conditional probability is computed as follows:\n",
    "$$\n",
    "P(A|B) = \\frac{P(A\\cap B)}{P(B)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e564d1",
   "metadata": {},
   "source": [
    "# II. Advanced Topics in Probability <a name = \"\"></a>\n",
    "## 1. Bayes' theorem\n",
    "### a) Overview of Bayes' theorem\n",
    "1. As an example, consider the likelihood of being colorblind in humans, we know that the chance of someone being colorblind is 4.25%, and the probability of a male being colorblind is 8%. Does it mean:\n",
    "    * Any colorblind person is 8% likely to be male? Or,\n",
    "    * Any male is 8% likely to be colorblind?\n",
    "    \n",
    "    \n",
    "2. We can reframe our questions to become:\n",
    "    * What is the likelihood of any colorblind person to be male?\n",
    "    * What is the likelihood of any male to be colorblind?\n",
    "    \n",
    "    \n",
    "3. These questions can be easily answered using the famous Bayes' theorem:\n",
    "$$\n",
    "P(A|B) = \\frac{P(A)\\times P(B|A)}{P(B)}\n",
    "$$\n",
    "\n",
    "***\n",
    "Likelihood of being colorblind: $P(blind) = 4.25\\% = 0.0425$\n",
    "\n",
    "Likelihood of a male being colorblind: $P(blind|male) = 8\\% = 0.08$\n",
    "\n",
    "Likelihood of being a male: $P(male) = 50\\% = 0.5$\n",
    "\n",
    "Likelihood of a colorblind being male: \n",
    "$$\n",
    "P(male|colorblind) = \\frac{P(male)\\times P(blind|male)}{P(blind)} = \\frac{0.08 \\times 0.5}{0.0425} = 0.9411\n",
    "$$\n",
    "\n",
    "***\n",
    "\n",
    "4. We can chain several conditional that affect an event of interest, assuming each condition is independent of the other conditions.\n",
    "\n",
    "<div>\n",
    "    <img src = \"images/data-science-bayes-theorem.jpg\" width  = 50%/>\n",
    "    </div>\n",
    "\n",
    "Figure 1: Visualization of Bayes' theorem. We can intepret this theorem as an approach to revise and update our probability of an event occurring after taking into consideration new information.\n",
    "\n",
    "### b) Properties of Bayesian probability\n",
    "\n",
    "## 2. Probability Distribution\n",
    "### a) What is  a probability distribution\n",
    "1. A probability distribution is a description of how likely a random variable or set of random variables is to take on each of its possible states. \n",
    "\n",
    "\n",
    "2. We describes probability distribution based on th\n",
    "\n",
    "## 3. Expectation, Variance and Covariance\n",
    "### a) Expectation (expected value)\n",
    "1. Consider a random variable $X$ taking in the possible values $x_1$, $x_2$,... that are described by a function $f(x)$, the expectation of a function $f(x)$  with a respect to a probability distribution $P(x)$ is the average or mean value that $f$ takes on when $x$ is drawn from $P$. We can apply the same definition for a random variable $X$ taking possible values that are drawn from a distribution $P(X)$, but cannot be described by any arbitrary function $f(x)$.\n",
    "\n",
    "\n",
    "2. Depends on the variable's type being discrete or continuous, we have two different methods to compute the expected value:\n",
    "    * For discrete variables, the expected value is a weighted average.\n",
    "$$\n",
    "E[X] = \\sum_ix_iP{X = x_i}\n",
    "$$\n",
    "or,\n",
    "$$\n",
    "E[f(x)] = \\sum_x P(x)f(x)\n",
    "$$\n",
    "    * For continuous variables, the expected value is the integral of the probability distribution function $P(X)$ and the function $f(x)$.\n",
    "$$\n",
    "E[f(x)] = \\int_{-\\infty}^{\\infty} P(x)f(x)\n",
    "$$\n",
    "\n",
    "\n",
    "3. As an example, considering the value $X$ we get from rolling of a dice, we know that all possible values are \"1\", \"2\", \"3\", \"4\", \"5\" and \"6\". Each possible value has a chance of $\\frac{1}{6}$ of taking place. Thus, the expected value is:\n",
    "$$\n",
    "E[X] =\\frac{1}{6}\\times1 + \\frac{1}{6}\\times2  + \\frac{1}{6}\\times3 + \\frac{1}{6}\\times4 + \\frac{1}{6}\\times5 + \\frac{1}{6}\\times6 = 3.5\n",
    "$$\n",
    "\n",
    "\n",
    "4. Another fun example is computing the expected value of a lottery (in this case, the Eurojackpot) to determine whether it worths buying. The Eurojackpot is a transnational European lottery where the prize starts at 10,000,000€ and can roll over up to 90,000,000€. Playing the Eurojackpot costs 2€ per line. Considering the pot of 47,000,000€, we can compute the expected value of this pot by multiplying the odds of winning for each prize, and sum all products. The resulting expected value is 9.84€ meaning if we play this pot, we are expected to lose 9.84 - 2 = 7.84€. Therefore, it is not worth buying at this stage.\n",
    "\n",
    "<div>\n",
    "    <img src = \"images/eurojackpot.png\" width = 80%/>\n",
    "    </div>\n",
    "    \n",
    "Figure 2: An example of computing expected value of a pot in the Eurojackpot lottery. Noted that the odds mentioned here is before October 10th 2014. Since October 10th 2014, the odds have been adjusted to decreased the chance of winning.\n",
    "\n",
    "5. Expectations are linear. For example, consider two functions $f(x)$ and $g(x)$:\n",
    "$$\n",
    "E[\\alpha f(x) + \\beta g(x)] = \\alpha E[f(x)] + \\beta E[g(x)]\n",
    "$$\n",
    "\n",
    "### b) Variance\n",
    "1. Considering a random variable $X$ taking possible values that can be described by a function $f(x)$ and drawing from a probability distribution $P(x)$, the variance gives a measure of how much the values of a function vary as we sample different values of $X$ from $P(x)$:\n",
    "$$\n",
    "Var(f(x)) = E[(f(x) - E[f(x)])^2]\n",
    "$$\n",
    "\n",
    "\n",
    "2. We can intepret the variance for discrete random variable $X = [x_1,...,x_n]$ and continuous random variable $f(x)$ as follows:\n",
    "$$\n",
    "Var(X) = \\sum x^2P(X) - E^2(X)\n",
    "$$\n",
    "\n",
    "$$\n",
    "Var(X) = \\int_{-\\infty}^{\\infty} x^2f(x)dx - E^2[f(x)]\n",
    "$$\n",
    "\n",
    "2. As an example, considering the rolling of a dice, we compute its variance to be 2.92.\n",
    "<div>\n",
    "    <img src = \"images/variance.png\" width = 50%/>\n",
    "    </div>\n",
    "\n",
    "Figure 3: An example of computing a variance for rolling of a dice.\n",
    "\n",
    "3. Noted that this definition of variance is similar to that in statistics.\n",
    "\n",
    "### c) Covariance\n",
    "1. Considering two random variables $X$ and $Y$ taking possible values that can be described by two functions $f(x)$ and $g(y)$ and drawing from two probability distributions $P(x)$ and $P(y)$, respectively. The covariance between $X$ and $Y$ gives us some sense of how much two values are linearly related to each other, as well as the scale of these variables:\n",
    "$$\n",
    "Cov[f(x), g(x)] = E[[f(x) - E[f(x)]],[g(x) - E[g(x)]]]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595268c7",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "## 1. How the joint probabilites work\n",
    "\n",
    "## 2. Revisiting conditional probabilities\n",
    "\n",
    "## 3. Revisiting the product rule\n",
    "Consider a joint probability $P(\\mathbf{x})$ consisting of many smaller probabilities $[p(x^{(1)}),..., p(x^{(n)})]$, we can generalize the product rule as. \n",
    "$$\n",
    "P(\\mathbf{x}) = P(x^{(1)},...,x^{(n)}) = P(x^{(1)})\\prod_{i = 2}^n P(x^{i}|x^{(1)},...,x^{(n)}) \n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
